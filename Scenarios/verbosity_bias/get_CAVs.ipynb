{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import shortuuid\n",
    "import random\n",
    "from torch.distributions.normal import Normal\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import copy\n",
    "from fastchat.conversation import get_conv_template\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func define\n",
    "# form inputs\n",
    "def get_inputs(tokenizer, sentence):\n",
    "    DEFAULT_TEMPLATE = get_conv_template(\"vicuna_v1.1\")\n",
    "    # DEFAULT_TEMPLATE = get_conv_template(\"llama-2\")\n",
    "    DEFAULT_TEMPLATE.sep2 = DEFAULT_TEMPLATE.sep2.strip()\n",
    "    DEFAULT_TEMPLATE.append_message(DEFAULT_TEMPLATE.roles[0], sentence)\n",
    "    DEFAULT_TEMPLATE.append_message(DEFAULT_TEMPLATE.roles[1], None)\n",
    "    prompt = DEFAULT_TEMPLATE.get_prompt()\n",
    "    # print(prompt)\n",
    "    indexed_tokens = tokenizer.encode(prompt)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).cuda()\n",
    "    return tokens_tensor, indexed_tokens\n",
    "\n",
    "def get_activation_hook(layer_name,activations):\n",
    "    def hook(model, input, output):\n",
    "        activations[layer_name] = output[0][-1, -1, :].cpu()\n",
    "    return hook\n",
    "\n",
    "def get_activations(model, tokenizer, prompt):\n",
    "    inputs = get_inputs(tokenizer, prompt)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        activations={}\n",
    "        handles=[]\n",
    "        for i, block in enumerate(model.model.layers):\n",
    "            handles.append(block.register_forward_hook(get_activation_hook(i,activations)))\n",
    "        p = model(inputs[0].to(model.device), output_attentions=True, return_dict=True)\n",
    "        for hook in handles:\n",
    "            hook.remove()\n",
    "        return activations,p\n",
    "\n",
    "def get_subsequent_activation_hook(layer_name,activations):\n",
    "    def hook(model, input, output):\n",
    "        if layer_name not in activations:\n",
    "            activations[layer_name] = []\n",
    "        activations[layer_name].append(output[0][-1, -1, :].cpu())\n",
    "    return hook\n",
    "\n",
    "def get_subsequent_activations_archive(model,tokenizer,prompt): #OOM\n",
    "    inputs = get_inputs(tokenizer, prompt)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        activations={}\n",
    "        handles=[]\n",
    "        for i, block in enumerate(model.model.layers):\n",
    "            handles.append(block.register_forward_hook(get_subsequent_activation_hook(i,activations)))\n",
    "        for i in range(256):\n",
    "            p = model(inputs[0].to(model.device), output_attentions=True, return_dict=True)\n",
    "            next_token = p.logits.argmax(-1)[0, -1].item()\n",
    "            if tokenizer.decode(next_token) == tokenizer.sep_token:\n",
    "                break\n",
    "            print(tokenizer.decode(next_token), end='')\n",
    "            inputs = (torch.cat([inputs[0], p.logits.argmax(-1)], dim=-1),)\n",
    "            del p  # 显式删除临时变量\n",
    "            torch.cuda.empty_cache()  # 清理显存缓存，确保显存释放\n",
    "        for hook in handles:\n",
    "            hook.remove()\n",
    "        return activations\n",
    "    \n",
    "def gen_model(model,tokenizer,prompt):\n",
    "    input_ids = get_inputs(tokenizer, prompt)\n",
    "    stop=len(input_ids[0])\n",
    "    gen_config = model.generation_config\n",
    "    with torch.no_grad():\n",
    "        attn_masks = torch.ones_like(input_ids[0]).to(model.device)\n",
    "        output_ids = model.generate(input_ids[0],\n",
    "                                    attention_mask=attn_masks,\n",
    "                                    generation_config=gen_config,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    # top_p=0.9,\n",
    "                                    do_sample=False,\n",
    "                                    max_new_tokens=48,\n",
    "                                    # temperature=0.7\n",
    "                                    )[0]\n",
    "        \n",
    "        gen_str=tokenizer.decode(output_ids[stop:]).strip()\n",
    "    return gen_str    \n",
    "\n",
    "def get_subsequent_activations(model, tokenizer, prompt):\n",
    "    \"\"\"\n",
    "    逐步流式生成并输出新 token 的模型生成函数。\n",
    "    \"\"\"\n",
    "    # 初始化输入\n",
    "    all_activations = []\n",
    "    handles=[]\n",
    "    input_ids = get_inputs(tokenizer, prompt)  # 获取初始输入\n",
    "    stop = len(input_ids[0])  # 记录初始长度，避免重新输出 prompt\n",
    "    input_ids = input_ids[0].to(model.device)  # 转移到设备\n",
    "    attention_mask = torch.ones_like(input_ids).to(model.device)  # 注意力掩码\n",
    "\n",
    "    generated_ids = input_ids  # 初始化生成序列\n",
    "    gen_config = model.generation_config  # 获取生成配置\n",
    "    eos_token_id = tokenizer.eos_token_id  # 结束 token ID\n",
    "    sep_token = tokenizer.sep_token  # 可选，停止生成的标志\n",
    "    \n",
    "    print(\"Generated text: \", end=\" \", flush=True)  # 提示生成开始\n",
    "    with torch.no_grad():\n",
    "        for _ in range(128):  # 限制最大生成 token 数\n",
    "            # 模型前向推理，获取 logits\n",
    "            activations={}\n",
    "            for i, block in enumerate(model.model.layers):\n",
    "                handles.append(block.register_forward_hook(get_activation_hook(i,activations)))\n",
    "                \n",
    "            outputs = model(\n",
    "                input_ids=generated_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                use_cache=True,  # 使用缓存提升性能\n",
    "                return_dict=True,\n",
    "            )\n",
    "            logits = outputs.logits[:, -1, :]  # 只取最后一个 token 的 logits\n",
    "\n",
    "            # 根据 logits 选择下一个 token（如采样或贪婪解码）\n",
    "            next_token_id = torch.argmax(logits, dim=-1).unsqueeze(0)  # 贪婪解码\n",
    "            next_token = tokenizer.decode(next_token_id.item())  # 解码新 token\n",
    "\n",
    "            # 输出新生成的 token\n",
    "            print(next_token, end=\" \", flush=True)\n",
    "\n",
    "            # 停止条件：检测到结束标志（如 eos 或 sep_token）\n",
    "            if next_token_id.item() == eos_token_id or next_token == sep_token:\n",
    "                break\n",
    "\n",
    "            # 更新生成序列，用于下一步推理\n",
    "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
    "            attention_mask = torch.cat(\n",
    "                [attention_mask, torch.ones_like(next_token_id)], dim=-1\n",
    "            )\n",
    "            all_activations.append(activations)\n",
    "            for hook in handles:\n",
    "                hook.remove()\n",
    "\n",
    "    print()  # 生成结束换行\n",
    "    # generated_text = tokenizer.decode(generated_ids[stop:], skip_special_tokens=True)\n",
    "    return all_activations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c14d9848ff04b5c938f6be473ab90ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get positive and negative activations\n",
    "# load model\n",
    "model_path = '/mnt/data/users/Lang_Gao/proj/models/vicuna-7b-v1.5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "positive_data = [i.strip() for i in open('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/data/simply_good.txt','r').readlines()]\n",
    "negative_data = [i.strip() for i in open('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/data/simply_bad.txt','r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "positive_data = sorted(positive_data, key=lambda x: len(x))\n",
    "negative_data = sorted(negative_data, key=lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "100%|██████████| 1000/1000 [01:21<00:00, 12.33it/s]\n",
      "100%|██████████| 1000/1000 [01:28<00:00, 11.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# obtain activations and form datasets\n",
    "from tqdm import tqdm\n",
    "data=[]\n",
    "labels=[]\n",
    "subsets=[]\n",
    "for i in tqdm(positive_data):\n",
    "    activations = get_activations(model, tokenizer, i)[0]\n",
    "    # move data\n",
    "    for k,v in activations.items():\n",
    "        data.append(v)\n",
    "        labels.append(1) # 1=positive\n",
    "        subsets.append(k)\n",
    "for i in tqdm(negative_data):\n",
    "    activations = get_activations(model, tokenizer, i)[0]\n",
    "    # move data\n",
    "    for k,v in activations.items():\n",
    "        data.append(v)\n",
    "        labels.append(0) # 0=negative\n",
    "        subsets.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2791805/1624740347.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  positive_data=torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/reduced_pos_data.pt')\n",
      "/tmp/ipykernel_2791805/1624740347.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  negative_data=torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/reduced_neg_data.pt')\n"
     ]
    }
   ],
   "source": [
    "# interrupt: using reduced data\n",
    "import torch\n",
    "positive_data=torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/reduced_pos_data_simply_good.pt')\n",
    "negative_data=torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/reduced_neg_data_simply_bad.pt')\n",
    "\n",
    "# obtain activations and form datasets\n",
    "from tqdm import tqdm\n",
    "data=[]\n",
    "labels=[]\n",
    "subsets=[]\n",
    "# move data\n",
    "for k in range(32):\n",
    "    for v in positive_data[k]:\n",
    "        \n",
    "        data.append(v)\n",
    "        labels.append(1) # 1=positive\n",
    "        subsets.append(k)\n",
    "    for v in negative_data[k]:\n",
    "        data.append(v)\n",
    "        labels.append(0) # 0=negative\n",
    "        subsets.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data into tensor\n",
    "data = torch.stack(data)\n",
    "labels = torch.tensor(labels)\n",
    "subsets = torch.tensor(subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formalize dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ActivationDataset(Dataset):\n",
    "    def __init__(self, data, labels,subset_idxs,device='cpu'):\n",
    "        self.data = data.to(device)\n",
    "        self.labels = labels.to(device)\n",
    "        self.subset_idxs = subset_idxs.to(device)\n",
    "        self.subset=None\n",
    "\n",
    "    def select_subset(self,subset_idx):\n",
    "        self.subset= ActivationDataset(self.data[self.subset_idxs==subset_idx], self.labels[self.subset_idxs==subset_idx], self.subset_idxs[self.subset_idxs==subset_idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.subset_idxs[idx] # for convenient check\n",
    "    \n",
    "dataset=ActivationDataset(data,labels,subsets,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform data\n",
    "pos_reform_data={i:[] for i in range(32)}\n",
    "neg_reform_data={i:[] for i in range(32)}\n",
    "for item in dataset:\n",
    "    # print(item)\n",
    "    # break\n",
    "    if item[1]==1:\n",
    "        pos_reform_data[item[2].item()].append(item[0])\n",
    "    else:\n",
    "        neg_reform_data[item[2].item()].append(item[0])\n",
    "pos_data=[torch.stack(pos_reform_data[i]) for i in range(32)]\n",
    "neg_data=[torch.stack(neg_reform_data[i]) for i in range(32)]\n",
    "torch.save(pos_data,'/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/pos_data_simply_good.pt')\n",
    "torch.save(neg_data,'/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/neg_data_simply_bad.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a logistic regression model:\n",
    "# input: 4096dim vec\n",
    "# output a prob of binary classification\n",
    "# structure: single mlp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义 Logistic Regression 模型\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim=4096):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # 单层 MLP (全连接层)\n",
    "        self.fc = nn.Linear(input_dim, 1)  # 输出为 1，用于二元分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        x = self.fc(x)          # 全连接层\n",
    "        x = torch.sigmoid(x)    # 使用 sigmoid 激活函数，输出概率值\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2794, -1.9551, -0.2962,  ..., -0.5957, -1.8432, -0.6108],\n",
       "        device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " tensor(31, device='cuda:0'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select_subset(31)\n",
    "dataset.subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Layer 0: 100%|██████████| 1000/1000 [00:23<00:00, 41.84epoch/s, loss=0.69, val_acc=0.57]\n",
      "Training Layer 1: 100%|██████████| 1000/1000 [00:23<00:00, 41.95epoch/s, loss=0.71, val_acc=0.49]\n",
      "Training Layer 2: 100%|██████████| 1000/1000 [00:23<00:00, 41.76epoch/s, loss=0.647, val_acc=0.66]\n",
      "Training Layer 3: 100%|██████████| 1000/1000 [00:23<00:00, 41.81epoch/s, loss=0.667, val_acc=0.57]\n",
      "Training Layer 4: 100%|██████████| 1000/1000 [00:23<00:00, 41.75epoch/s, loss=1.18, val_acc=0.54]\n",
      "Training Layer 5: 100%|██████████| 1000/1000 [00:23<00:00, 42.01epoch/s, loss=1.08, val_acc=0.43]\n",
      "Training Layer 6: 100%|██████████| 1000/1000 [00:24<00:00, 41.48epoch/s, loss=0.743, val_acc=0.69]\n",
      "Training Layer 7: 100%|██████████| 1000/1000 [00:24<00:00, 41.35epoch/s, loss=0.634, val_acc=0.62]\n",
      "Training Layer 8: 100%|██████████| 1000/1000 [00:24<00:00, 41.17epoch/s, loss=1.22, val_acc=0.55]\n",
      "Training Layer 9: 100%|██████████| 1000/1000 [00:24<00:00, 41.24epoch/s, loss=1.13, val_acc=0.71]\n",
      "Training Layer 10: 100%|██████████| 1000/1000 [00:24<00:00, 41.65epoch/s, loss=0.817, val_acc=0.63]\n",
      "Training Layer 11: 100%|██████████| 1000/1000 [00:23<00:00, 41.80epoch/s, loss=2.56, val_acc=0.47]\n",
      "Training Layer 12: 100%|██████████| 1000/1000 [00:24<00:00, 41.65epoch/s, loss=0.646, val_acc=0.66]\n",
      "Training Layer 13: 100%|██████████| 1000/1000 [00:24<00:00, 41.53epoch/s, loss=0.775, val_acc=0.54]\n",
      "Training Layer 14: 100%|██████████| 1000/1000 [00:23<00:00, 41.93epoch/s, loss=1.9, val_acc=0.68]\n",
      "Training Layer 15: 100%|██████████| 1000/1000 [00:23<00:00, 41.91epoch/s, loss=49.8, val_acc=0.54]\n",
      "Training Layer 16: 100%|██████████| 1000/1000 [00:23<00:00, 42.11epoch/s, loss=0.785, val_acc=0.75]\n",
      "Training Layer 17: 100%|██████████| 1000/1000 [00:23<00:00, 42.42epoch/s, loss=49.5, val_acc=0.4]\n",
      "Training Layer 18: 100%|██████████| 1000/1000 [00:23<00:00, 41.80epoch/s, loss=8.62, val_acc=0.51]\n",
      "Training Layer 19: 100%|██████████| 1000/1000 [00:23<00:00, 42.07epoch/s, loss=50.5, val_acc=0.62]\n",
      "Training Layer 20: 100%|██████████| 1000/1000 [00:23<00:00, 41.84epoch/s, loss=50.2, val_acc=0.56]\n",
      "Training Layer 21: 100%|██████████| 1000/1000 [00:23<00:00, 41.95epoch/s, loss=49.8, val_acc=0.48]\n",
      "Training Layer 22: 100%|██████████| 1000/1000 [00:23<00:00, 41.72epoch/s, loss=50.4, val_acc=0.56]\n",
      "Training Layer 23: 100%|██████████| 1000/1000 [00:23<00:00, 41.74epoch/s, loss=49.9, val_acc=0.49]\n",
      "Training Layer 24: 100%|██████████| 1000/1000 [00:23<00:00, 41.70epoch/s, loss=49.8, val_acc=0.45]\n",
      "Training Layer 25: 100%|██████████| 1000/1000 [00:23<00:00, 41.70epoch/s, loss=49.7, val_acc=0.52]\n",
      "Training Layer 26: 100%|██████████| 1000/1000 [00:24<00:00, 41.63epoch/s, loss=49.9, val_acc=0.53]\n",
      "Training Layer 27: 100%|██████████| 1000/1000 [00:23<00:00, 41.68epoch/s, loss=49.8, val_acc=0.48]\n",
      "Training Layer 28: 100%|██████████| 1000/1000 [00:24<00:00, 41.65epoch/s, loss=50.1, val_acc=0.45]\n",
      "Training Layer 29: 100%|██████████| 1000/1000 [00:24<00:00, 41.60epoch/s, loss=49.7, val_acc=0.47]\n",
      "Training Layer 30: 100%|██████████| 1000/1000 [00:23<00:00, 41.68epoch/s, loss=49.5, val_acc=0.49]\n",
      "Training Layer 31: 100%|██████████| 1000/1000 [00:23<00:00, 41.73epoch/s, loss=46.7, val_acc=0.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15 Test Accuracy: 0.5300\n",
      "Layer 16 Test Accuracy: 0.5000\n",
      "Layer 17 Test Accuracy: 0.4800\n",
      "Layer 18 Test Accuracy: 0.5200\n",
      "Layer 19 Test Accuracy: 0.5400\n",
      "Layer 20 Test Accuracy: 0.4800\n",
      "Layer 21 Test Accuracy: 0.5300\n",
      "Layer 22 Test Accuracy: 0.4800\n",
      "Layer 23 Test Accuracy: 0.4800\n",
      "Layer 24 Test Accuracy: 0.4800\n",
      "Layer 25 Test Accuracy: 0.4900\n",
      "Layer 26 Test Accuracy: 0.5200\n",
      "Layer 27 Test Accuracy: 0.5200\n",
      "Layer 28 Test Accuracy: 0.5300\n",
      "Layer 29 Test Accuracy: 0.5200\n",
      "Layer 30 Test Accuracy: 0.5200\n",
      "Layer 31 Test Accuracy: 0.5200\n",
      "Layer 32 Test Accuracy: 0.5200\n",
      "Layer 33 Test Accuracy: 0.4900\n",
      "Layer 34 Test Accuracy: 0.5200\n",
      "Layer 35 Test Accuracy: 0.5700\n",
      "Layer 36 Test Accuracy: 0.4800\n",
      "Layer 37 Test Accuracy: 0.5200\n",
      "Layer 38 Test Accuracy: 0.5000\n",
      "Layer 39 Test Accuracy: 0.4600\n",
      "Layer 40 Test Accuracy: 0.5200\n",
      "Layer 41 Test Accuracy: 0.5000\n",
      "Layer 42 Test Accuracy: 0.6500\n",
      "Layer 43 Test Accuracy: 0.4800\n",
      "Layer 44 Test Accuracy: 0.5700\n",
      "Layer 45 Test Accuracy: 0.4800\n",
      "Layer 46 Test Accuracy: 0.4900\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.BCELoss()  # 二元交叉熵损失\n",
    "input_dim = 2  # 输入向量的维度\n",
    "num_epochs = 1000  # 训练轮数\n",
    "batch_size = 32\n",
    "best_models = []  # 存储每层验证集上表现最好的模型\n",
    "\n",
    "for layer in range(32):\n",
    "    # Prepare dataset\n",
    "    dataset.select_subset(layer)\n",
    "    assert dataset.subset[0][-1] == layer\n",
    "\n",
    "    # 划分训练集、验证集和测试集\n",
    "    total_size = len(dataset.subset)\n",
    "    val_size = int(0.05 * total_size)  # 5% 验证集\n",
    "    test_size = int(0.05 * total_size)  # 5% 测试集\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    train_set, val_set, test_set = random_split(dataset.subset, [train_size, val_size, test_size])\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Init model\n",
    "    model = LogisticRegressionModel(input_dim).to('cuda')\n",
    "    model.train()  # 训练模式\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.05)  # 随机梯度下降，学习率 0.01\n",
    "\n",
    "    # 记录验证集上最佳性能\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None  # 保存最佳模型的状态\n",
    "\n",
    "    # Train model\n",
    "    with tqdm(total=num_epochs, desc=f\"Training Layer {layer}\", unit=\"epoch\") as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0  # 累计损失\n",
    "\n",
    "            # 训练模型\n",
    "            for batch_idx, (data, labels, _) in enumerate(train_loader):\n",
    "                data, labels = data.to('cuda'), labels.to('cuda')  # 将数据放到 GPU\n",
    "                optimizer.zero_grad()  # 清零梯度\n",
    "                outputs = model(data)  # 前向传播\n",
    "                loss = criterion(outputs, labels.float().unsqueeze(1))  # 计算损失\n",
    "\n",
    "                loss.backward()  # 反向传播\n",
    "                optimizer.step()  # 更新权重\n",
    "                running_loss += loss.item()  # 累积损失\n",
    "\n",
    "            # 计算当前 epoch 的平均损失\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "            # 验证模型\n",
    "            model.eval()  # 验证时切换到评估模式\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():  # 禁用梯度计算\n",
    "                for val_data, val_labels, _ in val_loader:\n",
    "                    val_data, val_labels = val_data.to('cuda'), val_labels.to('cuda')\n",
    "                    val_outputs = model(val_data)\n",
    "                    val_predictions = (val_outputs >= 0.5).float()  # 转化为硬标签\n",
    "                    correct += (val_predictions.squeeze(1) == val_labels).sum().item()\n",
    "                    total += val_labels.size(0)\n",
    "            val_acc = correct / total  # 验证集准确率\n",
    "\n",
    "            # 如果验证集准确率更高，保存当前模型\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = deepcopy(model.state_dict())  # 保存当前模型参数\n",
    "\n",
    "            model.train()  # 恢复训练模式\n",
    "\n",
    "            # 更新进度条，显示当前 epoch 的损失和验证集准确率\n",
    "            pbar.set_postfix(loss=avg_loss, val_acc=val_acc)\n",
    "            pbar.update(1)  # 更新进度条\n",
    "\n",
    "    # 保存每层验证集上表现最好的模型\n",
    "    best_model = LogisticRegressionModel(input_dim).to('cuda')\n",
    "    best_model.load_state_dict(best_model_state)  # 加载最佳模型参数\n",
    "    best_models.append(best_model)  # 保存最佳模型\n",
    "\n",
    "    # 清理当前模型以释放 GPU 内存\n",
    "    del model\n",
    "    del optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 测试模型\n",
    "for layer, model in enumerate(best_models, start=15):\n",
    "    model.eval()  # 测试时切换到评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for test_data, test_labels, _ in test_loader:\n",
    "            test_data, test_labels = test_data.to('cuda'), test_labels.to('cuda')\n",
    "            test_outputs = model(test_data)\n",
    "            test_predictions = (test_outputs >= 0.5).float()  # 转化为硬标签\n",
    "            correct += (test_predictions.squeeze(1) == test_labels).sum().item()\n",
    "            total += test_labels.size(0)\n",
    "    test_acc = correct / total  # 测试集准确率\n",
    "    print(f\"Layer {layer} Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKlearn-based CAV extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0 Accuracy: 0.8475\n",
      "layer1 Accuracy: 0.8425\n",
      "layer2 Accuracy: 0.9075\n",
      "layer3 Accuracy: 0.9600\n",
      "layer4 Accuracy: 0.9900\n",
      "layer5 Accuracy: 0.9925\n",
      "layer6 Accuracy: 0.9950\n",
      "layer7 Accuracy: 0.9950\n",
      "layer8 Accuracy: 0.9950\n",
      "layer9 Accuracy: 0.9950\n",
      "layer10 Accuracy: 0.9950\n",
      "layer11 Accuracy: 0.9950\n",
      "layer12 Accuracy: 0.9950\n",
      "layer13 Accuracy: 0.9950\n",
      "layer14 Accuracy: 0.9975\n",
      "layer15 Accuracy: 0.9975\n",
      "layer16 Accuracy: 0.9975\n",
      "layer17 Accuracy: 0.9975\n",
      "layer18 Accuracy: 0.9975\n",
      "layer19 Accuracy: 0.9975\n",
      "layer20 Accuracy: 0.9975\n",
      "layer21 Accuracy: 0.9975\n",
      "layer22 Accuracy: 0.9975\n",
      "layer23 Accuracy: 0.9950\n",
      "layer24 Accuracy: 0.9950\n",
      "layer25 Accuracy: 0.9950\n",
      "layer26 Accuracy: 0.9975\n",
      "layer27 Accuracy: 0.9950\n",
      "layer28 Accuracy: 0.9975\n",
      "layer29 Accuracy: 0.9975\n",
      "layer30 Accuracy: 0.9975\n",
      "layer31 Accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "accs=[]\n",
    "all_logreg = []\n",
    "# 将数据从 GPU 转移到 CPU 并转换为 numpy 数组\n",
    "for layer in range(32):\n",
    "    dataset.select_subset(layer)\n",
    "    data_cpu = dataset.subset.data.cpu().numpy()\n",
    "    labels_cpu = dataset.subset.labels.cpu().numpy()\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_cpu, labels_cpu, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 初始化逻辑回归模型\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    # 训练模型\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # 预测\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accs.append(accuracy)\n",
    "    print(f\"layer{layer} Accuracy: {accuracy:.4f}\")\n",
    "    all_logreg.append(deepcopy(log_reg))\n",
    "    del log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 14, Accuracy: 0.9975\n",
      "Index: 15, Accuracy: 0.9975\n",
      "Index: 16, Accuracy: 0.9975\n",
      "Index: 17, Accuracy: 0.9975\n",
      "Index: 18, Accuracy: 0.9975\n",
      "Index: 19, Accuracy: 0.9975\n",
      "Index: 20, Accuracy: 0.9975\n",
      "Index: 21, Accuracy: 0.9975\n",
      "Index: 22, Accuracy: 0.9975\n",
      "Index: 26, Accuracy: 0.9975\n",
      "Index: 28, Accuracy: 0.9975\n",
      "Index: 29, Accuracy: 0.9975\n",
      "Index: 30, Accuracy: 0.9975\n",
      "Index: 31, Accuracy: 0.9975\n",
      "Index: 6, Accuracy: 0.995\n",
      "Index: 7, Accuracy: 0.995\n",
      "Index: 8, Accuracy: 0.995\n",
      "Index: 9, Accuracy: 0.995\n",
      "Index: 10, Accuracy: 0.995\n",
      "Index: 11, Accuracy: 0.995\n",
      "Index: 12, Accuracy: 0.995\n",
      "Index: 13, Accuracy: 0.995\n",
      "Index: 23, Accuracy: 0.995\n",
      "Index: 24, Accuracy: 0.995\n",
      "Index: 25, Accuracy: 0.995\n",
      "Index: 27, Accuracy: 0.995\n",
      "Index: 5, Accuracy: 0.9925\n",
      "Index: 4, Accuracy: 0.99\n",
      "Index: 3, Accuracy: 0.96\n",
      "Index: 2, Accuracy: 0.9075\n",
      "Index: 0, Accuracy: 0.8475\n",
      "Index: 1, Accuracy: 0.8425\n"
     ]
    }
   ],
   "source": [
    "valid_dircs\n",
    "sorted_accs = sorted(enumerate(accs), key=lambda x: x[1], reverse=True)\n",
    "for idx, value in sorted_accs:\n",
    "    print(f\"Index: {idx}, Accuracy: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [torch.tensor(log_reg.coef_).squeeze() for log_reg in all_logreg]\n",
    "weights_tensor_list = [w for w in weights]\n",
    "torch.save(weights_tensor_list,'/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/cavs_simply_good_bad.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2791805/4200862191.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/cavs_length.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0037, -0.0147, -0.0138,  ..., -0.0036,  0.0276, -0.0007]),\n",
       " tensor([-0.0236, -0.0168, -0.0200,  ...,  0.0079, -0.0116, -0.0190]),\n",
       " tensor([-0.0241, -0.0123, -0.0055,  ...,  0.0132,  0.0051,  0.0043]),\n",
       " tensor([-0.0194,  0.0142, -0.0126,  ...,  0.0195, -0.0055,  0.0088]),\n",
       " tensor([-0.0118, -0.0060,  0.0106,  ...,  0.0272, -0.0093, -0.0076]),\n",
       " tensor([-0.0167, -0.0020,  0.0057,  ...,  0.0152, -0.0017,  0.0078]),\n",
       " tensor([ 0.0097, -0.0115, -0.0031,  ..., -0.0041, -0.0034, -0.0057]),\n",
       " tensor([ 0.0057, -0.0185, -0.0208,  ...,  0.0011, -0.0134, -0.0049]),\n",
       " tensor([-0.0103, -0.0162, -0.0062,  ...,  0.0109, -0.0029, -0.0049]),\n",
       " tensor([-0.0082, -0.0094,  0.0133,  ...,  0.0108,  0.0025,  0.0023]),\n",
       " tensor([ 0.0058, -0.0067,  0.0078,  ...,  0.0139,  0.0025,  0.0042]),\n",
       " tensor([ 0.0057, -0.0022,  0.0139,  ..., -0.0033,  0.0088, -0.0180]),\n",
       " tensor([-0.0081,  0.0042,  0.0146,  ..., -0.0040,  0.0103, -0.0026]),\n",
       " tensor([-0.0052, -0.0053, -0.0059,  ...,  0.0018,  0.0080, -0.0067]),\n",
       " tensor([ 0.0087, -0.0050,  0.0016,  ..., -0.0025, -0.0022, -0.0008]),\n",
       " tensor([ 0.0235, -0.0083,  0.0020,  ...,  0.0012, -0.0055,  0.0009]),\n",
       " tensor([ 0.0040, -0.0068,  0.0064,  ...,  0.0072, -0.0011, -0.0051]),\n",
       " tensor([-0.0113, -0.0124, -0.0014,  ...,  0.0070, -0.0081, -0.0064]),\n",
       " tensor([-0.0008, -0.0166, -0.0090,  ...,  0.0034, -0.0219, -0.0167]),\n",
       " tensor([-0.0006, -0.0089, -0.0131,  ...,  0.0204, -0.0216, -0.0103]),\n",
       " tensor([ 0.0083, -0.0054, -0.0006,  ...,  0.0065, -0.0070, -0.0038]),\n",
       " tensor([ 0.0087, -0.0084,  0.0076,  ...,  0.0044, -0.0145,  0.0005]),\n",
       " tensor([ 0.0148, -0.0171, -0.0017,  ...,  0.0114, -0.0207, -0.0011]),\n",
       " tensor([ 0.0051, -0.0189, -0.0066,  ...,  0.0032, -0.0150,  0.0119]),\n",
       " tensor([ 0.0054, -0.0170,  0.0010,  ...,  0.0080, -0.0166,  0.0175]),\n",
       " tensor([ 0.0068, -0.0251, -0.0134,  ..., -0.0081, -0.0227,  0.0178]),\n",
       " tensor([ 0.0182, -0.0217, -0.0154,  ..., -0.0047, -0.0200,  0.0108]),\n",
       " tensor([ 0.0105, -0.0180, -0.0132,  ..., -0.0076, -0.0235,  0.0230]),\n",
       " tensor([ 0.0127, -0.0237, -0.0228,  ...,  0.0058, -0.0094,  0.0193]),\n",
       " tensor([ 0.0193, -0.0124, -0.0013,  ..., -0.0021, -0.0260, -0.0015]),\n",
       " tensor([-0.0009, -0.0065,  0.0188,  ..., -0.0094, -0.0061,  0.0015]),\n",
       " tensor([ 0.0157, -0.0298,  0.0082,  ..., -0.0182, -0.0097,  0.0156])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/cavs_length.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0561, -0.0199,  0.0241,  ...,  0.0231, -0.0102,  0.0173],\n",
       "         [-0.0562, -0.0206,  0.0216,  ...,  0.0220, -0.0154,  0.0184],\n",
       "         [-0.0546, -0.0227,  0.0148,  ...,  0.0211, -0.0092,  0.0155],\n",
       "         ...,\n",
       "         [-0.0464, -0.0305,  0.0067,  ...,  0.0178, -0.0087,  0.0136],\n",
       "         [-0.0491, -0.0295,  0.0097,  ...,  0.0201, -0.0114,  0.0133],\n",
       "         [-0.0502, -0.0304,  0.0107,  ...,  0.0201, -0.0099,  0.0134]]),\n",
       " tensor([[-0.0706, -0.0041,  0.0222,  ...,  0.0173, -0.0060,  0.0029],\n",
       "         [-0.0757, -0.0035,  0.0211,  ...,  0.0191, -0.0179,  0.0031],\n",
       "         [-0.0791,  0.0043,  0.0129,  ...,  0.0140, -0.0065,  0.0205],\n",
       "         ...,\n",
       "         [-0.0687, -0.0253, -0.0131,  ...,  0.0062, -0.0106,  0.0273],\n",
       "         [-0.0726, -0.0248, -0.0091,  ...,  0.0054, -0.0208,  0.0236],\n",
       "         [-0.0721, -0.0249, -0.0107,  ...,  0.0060, -0.0188,  0.0235]]),\n",
       " tensor([[-0.0469,  0.0483,  0.0085,  ..., -0.0172,  0.0357,  0.0558],\n",
       "         [-0.0528,  0.0461,  0.0095,  ..., -0.0121,  0.0141,  0.0398],\n",
       "         [-0.0392,  0.0562,  0.0136,  ...,  0.0274,  0.0340,  0.0765],\n",
       "         ...,\n",
       "         [-0.0793,  0.0259, -0.0400,  ..., -0.0033,  0.0482,  0.0724],\n",
       "         [-0.0797,  0.0290, -0.0109,  ...,  0.0005,  0.0090,  0.0705],\n",
       "         [-0.0769,  0.0247, -0.0167,  ...,  0.0006,  0.0153,  0.0770]]),\n",
       " tensor([[-0.0558,  0.0055,  0.0088,  ...,  0.0030,  0.0581,  0.0089],\n",
       "         [-0.0740, -0.0265,  0.0123,  ...,  0.0145,  0.0148,  0.0032],\n",
       "         [-0.1058, -0.0522,  0.0081,  ...,  0.0413,  0.0375,  0.0841],\n",
       "         ...,\n",
       "         [-0.1277, -0.0650, -0.0546,  ...,  0.0607,  0.0299,  0.0890],\n",
       "         [-0.1452, -0.0453, -0.0315,  ...,  0.0648, -0.0205,  0.0873],\n",
       "         [-0.1457, -0.0475, -0.0081,  ...,  0.0724, -0.0179,  0.0970]]),\n",
       " tensor([[-0.1236, -0.0110,  0.0469,  ...,  0.0152,  0.0370,  0.0277],\n",
       "         [-0.1482, -0.0518,  0.0452,  ...,  0.0099,  0.0137,  0.0205],\n",
       "         [-0.1107, -0.0674,  0.0705,  ...,  0.0344,  0.0244,  0.1005],\n",
       "         ...,\n",
       "         [-0.1484, -0.0609, -0.0279,  ...,  0.0053, -0.0208,  0.1053],\n",
       "         [-0.1654, -0.0494, -0.0034,  ...,  0.0234, -0.0858,  0.1180],\n",
       "         [-0.1765, -0.0588,  0.0073,  ...,  0.0382, -0.1087,  0.1225]]),\n",
       " tensor([[-0.1508,  0.0732,  0.0643,  ...,  0.0014, -0.0512,  0.0752],\n",
       "         [-0.1284, -0.0956, -0.0274,  ..., -0.0277,  0.0161,  0.0875],\n",
       "         [-0.0732, -0.0708,  0.0713,  ..., -0.0748,  0.1259,  0.0590],\n",
       "         ...,\n",
       "         [-0.2141, -0.0622, -0.0789,  ..., -0.0313,  0.0275,  0.0779],\n",
       "         [-0.1965, -0.0695, -0.0520,  ...,  0.0082, -0.0321,  0.1112],\n",
       "         [-0.2100, -0.0813, -0.0226,  ...,  0.0243, -0.0596,  0.0821]]),\n",
       " tensor([[-0.2034,  0.0919,  0.1181,  ...,  0.0400,  0.0547,  0.1410],\n",
       "         [-0.1961, -0.0506,  0.0612,  ...,  0.0069,  0.1113,  0.1203],\n",
       "         [-0.0925, -0.0158,  0.1793,  ..., -0.0095,  0.1341,  0.1387],\n",
       "         ...,\n",
       "         [-0.1953, -0.0176,  0.0153,  ..., -0.0357,  0.0777,  0.1062],\n",
       "         [-0.1987, -0.0488,  0.0410,  ..., -0.0110,  0.0206,  0.1660],\n",
       "         [-0.2181, -0.0407,  0.0599,  ...,  0.0033,  0.0149,  0.1342]]),\n",
       " tensor([[-0.2768,  0.1549, -0.0596,  ...,  0.0414,  0.0327,  0.2107],\n",
       "         [-0.2167,  0.0077, -0.0532,  ...,  0.0902,  0.1026,  0.1241],\n",
       "         [-0.0099, -0.0229,  0.0288,  ...,  0.0150,  0.0551,  0.2508],\n",
       "         ...,\n",
       "         [-0.1665,  0.0278, -0.0043,  ..., -0.0471,  0.0257,  0.2315],\n",
       "         [-0.1775,  0.0283, -0.0132,  ...,  0.0128, -0.0292,  0.3010],\n",
       "         [-0.1729,  0.0066,  0.0037,  ...,  0.0338, -0.0506,  0.2593]]),\n",
       " tensor([[-0.1990,  0.0410, -0.1511,  ...,  0.2569,  0.0507,  0.1807],\n",
       "         [-0.2581, -0.0907, -0.0966,  ...,  0.1977,  0.1373,  0.0844],\n",
       "         [-0.0540, -0.0833, -0.0779,  ...,  0.1347,  0.0658,  0.2809],\n",
       "         ...,\n",
       "         [-0.2199, -0.0512, -0.2295,  ..., -0.0586, -0.1832,  0.2750],\n",
       "         [-0.1926, -0.1387, -0.2624,  ..., -0.0014, -0.2760,  0.3320],\n",
       "         [-0.1939, -0.1495, -0.2407,  ..., -0.0152, -0.3307,  0.3054]]),\n",
       " tensor([[-0.2089, -0.0227, -0.2427,  ...,  0.0629,  0.1583,  0.0203],\n",
       "         [-0.3169, -0.2732,  0.0472,  ...,  0.0375,  0.2232, -0.0011],\n",
       "         [ 0.0739, -0.2428, -0.1868,  ..., -0.1256,  0.0679,  0.2024],\n",
       "         ...,\n",
       "         [-0.2531, -0.3706,  0.1189,  ..., -0.1800, -0.2877,  0.0986],\n",
       "         [-0.2382, -0.3307,  0.0139,  ..., -0.1042, -0.2798,  0.1431],\n",
       "         [-0.2289, -0.3112,  0.0148,  ..., -0.1175, -0.3007,  0.1591]]),\n",
       " tensor([[-0.0234,  0.0067, -0.5239,  ...,  0.0224,  0.1355,  0.1545],\n",
       "         [-0.2228, -0.3558, -0.1859,  ..., -0.0202,  0.2318, -0.0792],\n",
       "         [-0.0755, -0.1809, -0.2784,  ...,  0.0321,  0.1383,  0.0610],\n",
       "         ...,\n",
       "         [-0.1895, -0.4363, -0.0612,  ..., -0.1396, -0.1831,  0.0987],\n",
       "         [-0.1304, -0.3548, -0.1471,  ..., -0.1667, -0.2098,  0.0778],\n",
       "         [-0.1075, -0.3377, -0.1390,  ..., -0.1110, -0.2236,  0.1106]]),\n",
       " tensor([[-0.3643,  0.0433, -0.6213,  ..., -0.1025,  0.0407,  0.1469],\n",
       "         [-0.5039, -0.3095, -0.1591,  ..., -0.1008,  0.2328,  0.0703],\n",
       "         [-0.3336, -0.1518, -0.3343,  ..., -0.0120,  0.0607,  0.0210],\n",
       "         ...,\n",
       "         [-0.4785, -0.4137, -0.1262,  ..., -0.1623, -0.3071,  0.1837],\n",
       "         [-0.4913, -0.3900, -0.1531,  ..., -0.1791, -0.1388,  0.1880],\n",
       "         [-0.4553, -0.4071, -0.1408,  ..., -0.0986, -0.1513,  0.2229]]),\n",
       " tensor([[-0.4846, -0.1347, -0.5502,  ..., -0.1794,  0.1974,  0.3364],\n",
       "         [-0.7296, -0.4502, -0.1293,  ..., -0.0378,  0.3648,  0.2505],\n",
       "         [-0.5688, -0.1051, -0.3708,  ..., -0.0741,  0.2017,  0.0889],\n",
       "         ...,\n",
       "         [-0.5888, -0.4885, -0.1956,  ..., -0.3512, -0.2233,  0.2148],\n",
       "         [-0.6811, -0.4618, -0.1778,  ..., -0.3770, -0.0810,  0.3086],\n",
       "         [-0.6504, -0.4863, -0.1958,  ..., -0.2856, -0.0832,  0.3894]]),\n",
       " tensor([[-0.4297, -0.0471, -0.5904,  ..., -0.0560,  0.1620,  0.1959],\n",
       "         [-0.5732, -0.2299, -0.1319,  ..., -0.0123,  0.4373,  0.2333],\n",
       "         [-0.2681, -0.1119, -0.2421,  ...,  0.0970,  0.1087,  0.1327],\n",
       "         ...,\n",
       "         [-0.7634, -0.3052, -0.0430,  ..., -0.2240, -0.0783,  0.3588],\n",
       "         [-0.8367, -0.3810,  0.0167,  ..., -0.2454,  0.0752,  0.4355],\n",
       "         [-0.7082, -0.3714,  0.0809,  ..., -0.1409,  0.0733,  0.4795]]),\n",
       " tensor([[-0.4789, -0.1591, -0.5388,  ...,  0.0194,  0.1256,  0.1605],\n",
       "         [-0.8479, -0.1511, -0.2022,  ...,  0.1875,  0.2970, -0.1532],\n",
       "         [-0.3506, -0.0313, -0.2437,  ..., -0.0120,  0.2467,  0.1781],\n",
       "         ...,\n",
       "         [-0.6463, -0.1486, -0.0601,  ..., -0.2108,  0.0275,  0.2917],\n",
       "         [-0.7574, -0.2668, -0.1234,  ..., -0.2220,  0.1655,  0.2881],\n",
       "         [-0.7261, -0.0949, -0.0539,  ..., -0.1173,  0.1072,  0.3242]]),\n",
       " tensor([[-0.3322, -0.2239, -0.4036,  ..., -0.2981,  0.1334,  0.1589],\n",
       "         [-0.9823, -0.0663, -0.1267,  ...,  0.0762,  0.4274,  0.0489],\n",
       "         [-0.4422,  0.0841,  0.0139,  ..., -0.0847,  0.3621,  0.4129],\n",
       "         ...,\n",
       "         [-0.6273, -0.2302,  0.1009,  ..., -0.6535,  0.1332,  0.4159],\n",
       "         [-0.6836, -0.2126, -0.1873,  ..., -0.5813,  0.2251,  0.3541],\n",
       "         [-0.6880, -0.1374, -0.0827,  ..., -0.4152,  0.2776,  0.4578]]),\n",
       " tensor([[-0.6520, -0.4263, -0.2302,  ..., -0.3881,  0.0329,  0.1077],\n",
       "         [-1.2441, -0.0875,  0.2394,  ..., -0.0606,  0.3375,  0.1310],\n",
       "         [-0.8370, -0.0453,  0.4069,  ..., -0.0532,  0.1983,  0.8105],\n",
       "         ...,\n",
       "         [-0.7637, -0.5164,  0.2953,  ..., -0.3656, -0.1401,  0.4977],\n",
       "         [-0.9318, -0.4248,  0.0643,  ..., -0.3823, -0.0364,  0.4942],\n",
       "         [-0.8880, -0.4719,  0.1825,  ..., -0.1037,  0.0163,  0.6170]]),\n",
       " tensor([[-1.0169e+00, -6.1406e-01, -3.1873e-03,  ..., -6.9104e-01,\n",
       "           5.6753e-02,  9.1417e-02],\n",
       "         [-1.5902e+00, -4.0584e-01,  5.8531e-01,  ..., -3.2870e-01,\n",
       "           3.9540e-01, -5.9069e-02],\n",
       "         [-8.4077e-01, -1.1007e-03,  5.6307e-01,  ..., -3.6937e-01,\n",
       "          -6.1139e-02,  6.9624e-01],\n",
       "         ...,\n",
       "         [-9.1445e-01, -5.5621e-01,  7.1644e-01,  ..., -7.8860e-01,\n",
       "          -8.7728e-02,  8.2070e-01],\n",
       "         [-1.1017e+00, -3.8188e-01,  4.7676e-01,  ..., -8.9386e-01,\n",
       "          -6.8644e-02,  8.3073e-01],\n",
       "         [-9.5564e-01, -4.9793e-01,  4.4482e-01,  ..., -5.7294e-01,\n",
       "           4.3570e-02,  8.5383e-01]]),\n",
       " tensor([[-1.0986, -0.8020,  0.1210,  ..., -0.7151, -0.1698,  0.0304],\n",
       "         [-1.3781, -0.6271,  0.8199,  ..., -0.7114,  0.2603, -0.0263],\n",
       "         [-0.8638, -0.0651,  0.4580,  ..., -0.3423, -0.1498,  0.5488],\n",
       "         ...,\n",
       "         [-1.1196, -0.3512,  0.6453,  ..., -0.9679, -0.2241,  0.8429],\n",
       "         [-1.3279, -0.0938,  0.5385,  ..., -0.8705, -0.2073,  0.9187],\n",
       "         [-1.0407, -0.2389,  0.4983,  ..., -0.6356, -0.2923,  0.9676]]),\n",
       " tensor([[-1.1158, -0.6943,  0.0910,  ..., -0.6345, -0.4410,  0.2586],\n",
       "         [-1.5880, -0.6251,  0.7973,  ..., -0.9113,  0.0812,  0.1655],\n",
       "         [-0.8759,  0.1027,  0.4679,  ..., -0.5116, -0.0563,  0.5566],\n",
       "         ...,\n",
       "         [-1.2090, -0.3601,  0.5855,  ..., -0.9521, -0.6600,  0.6609],\n",
       "         [-1.3953,  0.0097,  0.4217,  ..., -0.6881, -0.7333,  0.7253],\n",
       "         [-1.1895, -0.2436,  0.4565,  ..., -0.3893, -0.7372,  0.9453]]),\n",
       " tensor([[-1.2611, -0.9048,  0.1897,  ..., -0.5235, -0.5959,  0.3919],\n",
       "         [-1.7712, -0.8054,  0.8247,  ..., -0.5858, -0.1095, -0.0227],\n",
       "         [-0.9514, -0.0038,  0.6354,  ..., -0.6754, -0.2171,  0.6481],\n",
       "         ...,\n",
       "         [-1.5275, -0.0330,  0.9580,  ..., -0.7591, -0.7179,  0.8058],\n",
       "         [-1.8306,  0.4084,  0.5849,  ..., -0.5315, -0.9331,  0.8290],\n",
       "         [-1.5194,  0.0668,  0.5701,  ..., -0.3233, -0.9604,  1.0577]]),\n",
       " tensor([[-1.3427, -0.6535,  0.4524,  ..., -0.7642, -0.7173,  0.5279],\n",
       "         [-1.7571, -0.7411,  1.1282,  ..., -0.6493, -0.0726,  0.2121],\n",
       "         [-1.0219, -0.0228,  0.6863,  ..., -0.7537, -0.0830,  0.6149],\n",
       "         ...,\n",
       "         [-1.1264,  0.0494,  1.1609,  ..., -0.5275, -0.5678,  1.0685],\n",
       "         [-1.4518,  0.6246,  0.8445,  ..., -0.3260, -0.7716,  1.0334],\n",
       "         [-1.1902,  0.2396,  0.8571,  ..., -0.1616, -0.9370,  1.2257]]),\n",
       " tensor([[-0.8991, -0.7026,  0.9009,  ..., -0.9095, -0.9012,  0.3931],\n",
       "         [-1.3981, -0.7728,  1.4081,  ..., -0.9888, -0.2006,  0.2863],\n",
       "         [-1.2017, -0.0500,  0.7082,  ..., -0.8739, -0.2960,  0.5607],\n",
       "         ...,\n",
       "         [-1.0173,  0.0423,  1.0233,  ..., -0.2071, -0.6770,  1.3361],\n",
       "         [-1.4493,  0.4856,  0.5482,  ..., -0.1112, -0.9377,  1.2710],\n",
       "         [-1.1272,  0.1667,  0.6707,  ..., -0.0414, -1.1356,  1.3385]]),\n",
       " tensor([[-0.7117, -0.7011,  0.5781,  ..., -0.9157, -0.7189,  0.3199],\n",
       "         [-0.9644, -0.7354,  1.4531,  ..., -1.0944, -0.3353, -0.1480],\n",
       "         [-1.5295, -0.3319,  0.5508,  ..., -1.1045, -0.4410,  0.2995],\n",
       "         ...,\n",
       "         [-1.2523,  0.4454,  0.9479,  ..., -0.3598, -0.4952,  1.3695],\n",
       "         [-1.7542,  0.8924,  0.3967,  ..., -0.2841, -0.7313,  1.3354],\n",
       "         [-1.3181,  0.5526,  0.6274,  ..., -0.2258, -1.1062,  1.2781]]),\n",
       " tensor([[-0.7337, -0.4481,  0.8039,  ..., -0.7304, -0.2681,  0.0207],\n",
       "         [-1.5554, -0.6366,  1.4459,  ..., -1.0319, -0.1919, -0.1881],\n",
       "         [-1.3529, -0.2720,  0.5275,  ..., -1.5312, -0.5345,  0.6760],\n",
       "         ...,\n",
       "         [-1.5199,  0.0887,  0.7875,  ..., -0.4754, -0.4735,  1.5839],\n",
       "         [-1.8835,  0.5593,  0.2486,  ..., -0.2730, -0.7322,  1.5143],\n",
       "         [-1.5584,  0.3246,  0.5107,  ..., -0.3030, -0.9847,  1.5187]]),\n",
       " tensor([[-0.7359, -0.2570,  0.5068,  ..., -1.1042, -0.2798,  0.1355],\n",
       "         [-1.6338, -0.7012,  1.5150,  ..., -0.8442, -0.0058,  0.0299],\n",
       "         [-1.6061, -0.4905,  0.9116,  ..., -1.6855, -0.2562,  1.3361],\n",
       "         ...,\n",
       "         [-1.7489, -0.2627,  1.1067,  ..., -0.4426, -0.5134,  1.8901],\n",
       "         [-1.9719,  0.1154,  0.5771,  ..., -0.0955, -0.8268,  1.6705],\n",
       "         [-1.5406,  0.0827,  0.7495,  ..., -0.1382, -1.0850,  1.6811]]),\n",
       " tensor([[-1.1791, -0.3914,  0.2618,  ..., -1.4758, -0.1525,  0.5200],\n",
       "         [-2.1469, -1.2671,  1.4237,  ..., -1.2180,  0.0639, -0.1966],\n",
       "         [-1.4161, -0.4402,  0.9214,  ..., -2.0094, -0.3172,  1.3696],\n",
       "         ...,\n",
       "         [-1.8713, -0.3106,  0.9001,  ..., -0.6277, -0.9404,  2.1684],\n",
       "         [-2.1970, -0.1452,  0.3953,  ..., -0.3377, -1.3905,  1.9060],\n",
       "         [-1.7482, -0.1458,  0.5514,  ..., -0.4779, -1.5073,  1.8852]]),\n",
       " tensor([[-1.4800, -0.3569,  0.1838,  ..., -1.8163,  0.0826,  0.3637],\n",
       "         [-2.3804, -1.1778,  1.5920,  ..., -1.4154,  0.3881, -0.1030],\n",
       "         [-1.5560, -0.5662,  1.3223,  ..., -2.0873, -0.1895,  1.5254],\n",
       "         ...,\n",
       "         [-2.2123, -0.2866,  0.9934,  ..., -0.8450, -0.7747,  2.0082],\n",
       "         [-2.3798, -0.1615,  0.5175,  ..., -0.5325, -1.2365,  1.7179],\n",
       "         [-1.7840, -0.0518,  0.6650,  ..., -0.7222, -1.3494,  1.8470]]),\n",
       " tensor([[-1.6084, -0.4518,  0.2506,  ..., -1.8747,  0.2310, -0.2062],\n",
       "         [-2.4047, -1.0884,  1.3764,  ..., -1.4786,  0.4697, -0.3282],\n",
       "         [-1.5625, -0.8165,  1.0420,  ..., -2.2640, -0.0680,  1.5551],\n",
       "         ...,\n",
       "         [-2.2714, -0.5706,  0.9467,  ..., -0.6847, -1.1798,  2.2322],\n",
       "         [-2.2398, -0.3480,  0.6441,  ..., -0.4318, -1.7771,  1.8672],\n",
       "         [-1.4790, -0.2204,  0.7408,  ..., -0.8002, -1.8209,  2.0607]]),\n",
       " tensor([[-1.8446, -0.7437,  0.1849,  ..., -2.3093,  0.3542,  0.1372],\n",
       "         [-2.3408, -1.3750,  1.5414,  ..., -1.5164,  0.8358,  0.0036],\n",
       "         [-1.6413, -1.4246,  0.9939,  ..., -2.3917,  0.2187,  1.9681],\n",
       "         ...,\n",
       "         [-1.8325, -0.8681,  0.4346,  ..., -1.0276, -0.8491,  2.3527],\n",
       "         [-2.1652, -0.8458,  0.3166,  ..., -0.9054, -1.5486,  1.8478],\n",
       "         [-1.4185, -0.6921,  0.4187,  ..., -1.2677, -1.5301,  2.0603]]),\n",
       " tensor([[-2.0523, -1.7623,  0.0789,  ..., -3.0381,  0.2812, -0.1803],\n",
       "         [-2.4713, -2.0554,  1.4084,  ..., -1.5482,  0.5237, -0.3347],\n",
       "         [-2.0586, -2.0844,  1.0405,  ..., -2.5985, -0.0250,  1.5606],\n",
       "         ...,\n",
       "         [-1.4592, -1.3453,  0.7284,  ..., -1.2776, -0.9902,  2.0578],\n",
       "         [-1.7458, -1.7140,  0.5663,  ..., -1.2312, -1.5110,  1.6235],\n",
       "         [-1.2594, -1.3546,  0.6982,  ..., -1.4527, -1.2425,  1.8629]]),\n",
       " tensor([[-2.3946, -0.9845,  0.8593,  ..., -2.8194,  0.7269,  0.7676],\n",
       "         [-2.0229, -0.5258,  2.4865,  ..., -1.9234,  0.8178,  0.5270],\n",
       "         [-1.6833, -0.2764,  1.9547,  ..., -1.9815, -0.5966,  2.2174],\n",
       "         ...,\n",
       "         [-0.6472,  0.3301,  1.9257,  ..., -1.0555, -0.8605,  2.0333],\n",
       "         [-0.8625, -0.2229,  1.2235,  ..., -0.9577, -1.6641,  1.7022],\n",
       "         [-0.5475,  0.2781,  1.6355,  ..., -1.2654, -0.9870,  2.1421]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference data\n",
    "a=torch.load('/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/bkg_acts_alpaca_tensor.pt')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs=[]\n",
    "for model in models:\n",
    "    w=model.fc.weight.squeeze()\n",
    "    cavs.append(w/torch.norm(w))\n",
    "torch.save(cavs,'/mnt/data/users/Lang_Gao/proj/My_Proj/Fairness_Mechanisms/tensors/cavs_length.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencompass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
